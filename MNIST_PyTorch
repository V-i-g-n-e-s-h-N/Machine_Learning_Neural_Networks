import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision.datasets import MNIST
import matplotlib.pyplot as plt

torch.manual_seed(42)
torch.cuda.manual_seed(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")



# Dataset
train_dataset = MNIST(root = "./data", train = True, download = True)
val_dataset = MNIST(root = "./data", train = False, download = True)



# Dataset info
train_data = train_dataset.data
train_targets = train_dataset.targets
print(f"Train Data Shape: {train_data.shape}")
print(f"Train Targets Shape: {train_targets.shape}")

test_val_data = val_dataset.data
test_val_targets = val_dataset.targets
print(f"Val Data shape: {test_val_data.shape}")
print(f"Val Targets Shape: {test_val_targets.shape}")



# Dataset Splitting and DataLoaders
TEST_DATAPTS = int(0.5 * test_val_data.shape[0])
print(TEST_DATAPTS)

val_data = test_val_data[:TEST_DATAPTS]
test_data = test_val_data[TEST_DATAPTS:]

val_targets = test_val_targets[: TEST_DATAPTS]
test_targets = test_val_targets[TEST_DATAPTS :]

print(f"Val Data shape: {val_data.shape}")
print(f"Val Targets Shape: {val_targets.shape}")
print(f"Test Data Shape: {test_data.shape}")
print(f"Test Targets shape: {test_targets.shape}")



# Reshaping The Data and Preprocessing
train_data = train_data.reshape((train_data.shape[0], -1))
val_data = val_data.reshape((val_data.shape[0], -1))
test_data = test_data.reshape((test_data.shape[0], -1))

print(f"Reshaped train data: {train_data.shape}")
print(f"Reshaped val data: {val_data.shape}")
print(f"Reshaped test data: {test_data.shape}")



# Datasets and DataLoaders
class MnistDataset(Dataset):
  def __init__(self, data, targets):
    super().__init__()
    self.x = data
    self.y = targets
  def __getitem__(self, index):
    data, target = self.x[index], self.y[index]
    return data, target
  def __len__(self):
    return self.y.shape[0]

train_dataset = MnistDataset(train_data, train_targets)
val_dataset = MnistDataset(val_data, val_targets)
test_datase = MnistDataset(test_data, test_targets)

## DataLoaders
train_dataloader = DataLoader(dataset = train_dataset, shuffle=True, batch_size = 32)



#Model
class Simple_one(nn.Module):
  def __init__(self, num_classes):
    super().__init__()
    self.fc1 = nn.Linear(784, 512)
    self.fc2 = nn.Linear(512, 10)

  def forward(self, x):
    x = F.relu(self.fc1(x))
    x = F.softmax(self.fc2(x), dim = -1)
    return x



## Hyperparameters and Optimizer
model = Simple_one(10).to(device)
EPOCHS = 5
optimizer = optim.SGD(model.parameters(), lr = 1e-3)



 # Training Loop
train_losses = []
val_losses = []
val_accs = []
train_accs = []

for epoch in range(EPOCHS):
  tloss = 0
  tloss_num = 0
  total = 0
  correct = 0

  for batch_idx, data in enumerate(train_dataloader):
    x, y = data
    x = x.to(torch.float32).to(device)
    y = y.to(torch.long).to(device)

    optimizer.zero_grad()
    out = model(x)
    loss = F.cross_entropy(out, y)
    loss.backward()
    optimizer.step()

    # Running mean of Loss
    tloss += loss.detach().cpu()
    tloss_num += 1

    #Accuracy Calculation
    _, preds = torch.max(out.data, 1)
    total += y.shape[0]
    correct += (preds == y).sum().item()

  with torch.no_grad():
    val_data = val_data.to(torch.float32).to(device)
    val_targets = val_targets.to(torch.long).to(device)

    out = model(val_data)
    loss = F.cross_entropy(out, val_targets)

    _, preds = torch.max(out.data, 1)
    val_acc = (preds == val_targets).sum().item() / val_targets.shape[0]

  print(f"Epochs: {epoch} / {EPOCHS}")
  print(f"Train Loss: {tloss / tloss_num} Accuracy: {correct /total}")
  print(f"Val Loss: {loss} Accuracy: {val_acc}")

  train_losses.append(tloss / tloss_num)
  train_accs.append(correct / total)
  val_losses.append(loss)
  val_accs.append(val_acc)



# Testing the Dataset
with torch.no_grad():
  test_data = test_data.to(torch.float32).to(device)
  test_targets = test_targets.to(torch.long).to(device)

  out = model(test_data)
  loss = F.cross_entropy(out, test_targets)

  _, preds = torch.max(out.data, 1)
  test_acc = (preds == test_targets).sum().item() / test_targets.shape[0]

  print(f"Test Loss: {loss} Accuracy: {test_acc}")

